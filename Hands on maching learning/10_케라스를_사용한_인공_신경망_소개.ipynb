{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10. 케라스를 사용한 인공 신경망 소개.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wVoYhfCNh1ij"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "iris=load_iris()\n",
        "X=iris.data[:, (2,3)] #꽃입의 길이와 너비\n",
        "y=(iris.target==0).astype(int) #부채붓꽃 (Iris Setosa)인가?\n",
        "\n",
        "per_clf=Perceptron()\n",
        "per_clf.fit(X,y)\n",
        "\n",
        "y_pred=per_clf.predict([[2,0.5]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDgC9zNZiOOV",
        "outputId": "80ff5e60-bc06-4cf8-d3ad-ed5b2e833c4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "Xr-ZIdz_ifkn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcA2oEYglLBT",
        "outputId": "7f6bb68e-52f9-42e2-d75b-8e1b5c507813"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wcKrHiNqlMUa",
        "outputId": "29aa5d49-d83a-45d1-c351-ed333ae5fb7b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist=keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test)=fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzVY7zsIlNcH",
        "outputId": "4e2268a7-f079-4ccb-be31-126f4b763e2f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5c-DUzDldM0",
        "outputId": "2f38c450-25b0-4c77-e145-12f797f03461"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uk_F9YqlhtE",
        "outputId": "f8500ce5-e050-4c2e-9df9-97bd3fceb0e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train=X_train_full[:5000] / 255.0, X_train_full[5000:]/255.0\n",
        "y_valid, y_train=y_train_full[:5000] , y_train_full[5000:]\n",
        "X_test=X_test/255.0"
      ],
      "metadata": {
        "id": "ijZ_kNKTljGb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=[\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "bBEpvJ8TmF-a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[y_train[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YQNUGuIAmOOK",
        "outputId": "a33a0479-6187-4ef5-d021-0f7c35590cfb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Coat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28])) #입력 이미지를 1D 배열로 반환\n",
        "model.add(keras.layers.Dense(300, activation='relu'))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "cc2fmttzmUD6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ5gAaibmmH6",
        "outputId": "ecebdc95-29cb-4b52-cfc7-3cc52610694b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7ED__S3m5ft",
        "outputId": "e1fca82c-21aa-4a1d-a5e7-6bdbd4958816"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.flatten.Flatten at 0x7faad73ea210>,\n",
              " <keras.layers.core.dense.Dense at 0x7faad8cac7d0>,\n",
              " <keras.layers.core.dense.Dense at 0x7faad7479f50>,\n",
              " <keras.layers.core.dense.Dense at 0x7faad74794d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden1=model.layers[1]"
      ],
      "metadata": {
        "id": "M5x6mcBXnBOG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden1.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d6VSA5z3nDVn",
        "outputId": "33caef7e-2bad-4915-c51e-e2e9b36462aa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dense'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_layer('dense') is hidden1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3mWqmaWnEZd",
        "outputId": "92032267-76da-4323-e2d2-1695cdbc9f83"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases=hidden1.get_weights()"
      ],
      "metadata": {
        "id": "2VUT25E_nGjI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD7RATE1nKbn",
        "outputId": "892ee278-3185-496b-f4c3-8dafd93377fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.04322717,  0.03902113, -0.06311086, ..., -0.06457203,\n",
              "        -0.01163661, -0.04554011],\n",
              "       [ 0.04185635,  0.07000716,  0.039364  , ..., -0.04324093,\n",
              "        -0.02047697, -0.00172658],\n",
              "       [ 0.03642536,  0.01967604,  0.00910227, ..., -0.06284358,\n",
              "         0.03682935,  0.06892696],\n",
              "       ...,\n",
              "       [-0.04368523,  0.06808217,  0.06891116, ...,  0.07250923,\n",
              "         0.00166781, -0.06683511],\n",
              "       [-0.01699111, -0.04255198,  0.05535027, ..., -0.05955215,\n",
              "        -0.03960469, -0.02465028],\n",
              "       [-0.07068923,  0.03789703, -0.01797105, ..., -0.02517246,\n",
              "        -0.03666063, -0.04759493]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2h7U3E0nLU2",
        "outputId": "a1005fd2-7426-44db-844d-74030bdb1d37"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "biases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52LL06rwnNhE",
        "outputId": "97c7303d-6a19-4627-dd3b-c8f297637f0f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "biases.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNFuXFAsnOSB",
        "outputId": "1ea8efe1-373b-4dfd-c1d8-3ed116e39805"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=['accuracy']) #sgd의 기본값 lr=0.01"
      ],
      "metadata": {
        "id": "FXs_EvrjnO8i"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SSMtuU1nfO4",
        "outputId": "25a69ee2-983f-4fa0-ab52-7c205a89d765"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.7241 - accuracy: 0.7608 - val_loss: 0.5140 - val_accuracy: 0.8262\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4880 - accuracy: 0.8292 - val_loss: 0.4438 - val_accuracy: 0.8498\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4408 - accuracy: 0.8451 - val_loss: 0.4208 - val_accuracy: 0.8520\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4133 - accuracy: 0.8535 - val_loss: 0.3960 - val_accuracy: 0.8642\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3936 - accuracy: 0.8608 - val_loss: 0.3871 - val_accuracy: 0.8650\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3768 - accuracy: 0.8669 - val_loss: 0.3738 - val_accuracy: 0.8722\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3634 - accuracy: 0.8720 - val_loss: 0.3715 - val_accuracy: 0.8696\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3530 - accuracy: 0.8752 - val_loss: 0.3546 - val_accuracy: 0.8750\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3419 - accuracy: 0.8786 - val_loss: 0.3460 - val_accuracy: 0.8776\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3323 - accuracy: 0.8813 - val_loss: 0.3441 - val_accuracy: 0.8802\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3243 - accuracy: 0.8837 - val_loss: 0.3518 - val_accuracy: 0.8734\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3161 - accuracy: 0.8866 - val_loss: 0.3361 - val_accuracy: 0.8742\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3091 - accuracy: 0.8888 - val_loss: 0.3517 - val_accuracy: 0.8730\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3022 - accuracy: 0.8915 - val_loss: 0.3277 - val_accuracy: 0.8792\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2964 - accuracy: 0.8938 - val_loss: 0.3274 - val_accuracy: 0.8822\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2894 - accuracy: 0.8961 - val_loss: 0.3336 - val_accuracy: 0.8814\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2840 - accuracy: 0.8975 - val_loss: 0.3267 - val_accuracy: 0.8826\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2780 - accuracy: 0.8997 - val_loss: 0.3140 - val_accuracy: 0.8896\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2733 - accuracy: 0.9014 - val_loss: 0.3158 - val_accuracy: 0.8876\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2683 - accuracy: 0.9030 - val_loss: 0.3200 - val_accuracy: 0.8840\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2628 - accuracy: 0.9054 - val_loss: 0.3068 - val_accuracy: 0.8906\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2574 - accuracy: 0.9078 - val_loss: 0.3111 - val_accuracy: 0.8868\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2531 - accuracy: 0.9087 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2486 - accuracy: 0.9111 - val_loss: 0.3052 - val_accuracy: 0.8894\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2446 - accuracy: 0.9111 - val_loss: 0.2979 - val_accuracy: 0.8930\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2405 - accuracy: 0.9130 - val_loss: 0.2999 - val_accuracy: 0.8908\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2371 - accuracy: 0.9153 - val_loss: 0.3014 - val_accuracy: 0.8900\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2318 - accuracy: 0.9161 - val_loss: 0.3057 - val_accuracy: 0.8882\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2285 - accuracy: 0.9173 - val_loss: 0.2938 - val_accuracy: 0.8922\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2251 - accuracy: 0.9194 - val_loss: 0.3086 - val_accuracy: 0.8898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1) #수직축의 범위를 [0-1] 사이로 설정\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "e8rI5jWan8nv",
        "outputId": "5933eeaf-0ff2-454b-b940-3ca50032c66b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWn3S0hzoX45",
        "outputId": "15d71538-28b1-48d1-feab-7c6fc2058589"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.8849\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3329581916332245, 0.8848999738693237]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new=X_test[:3]\n",
        "y_proba=model.predict(X_new)\n",
        "y_proba.round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz0oBMj1o1lT",
        "outputId": "5a5f8f4f-358e-4f9e-8748-117470f88a43"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob=model.predict(X_new)\n",
        "predicted = y_prob.argmax(axis=-1)\n",
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puG_NoaXo6Xv",
        "outputId": "8935402c-5b04-47e0-a549-b91929138fa1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(class_names)[predicted]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tupt5g3TpIXm",
        "outputId": "28ae9c97-46bf-4fb8-84da-9c8d4d58d162"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_new=y_test[:3]\n",
        "y_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fxd6n0gpnoX",
        "outputId": "3244e1d0-85c4-47b5-deeb-26fbe57a5678"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#주택가격 사용\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "Eqlq-C8rpvMY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing=fetch_california_housing()"
      ],
      "metadata": {
        "id": "yoGKJqVhp-6t"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full, X_test, y_train_full, y_test=train_test_split(housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid=train_test_split(X_train_full, y_train_full)"
      ],
      "metadata": {
        "id": "PVQHmNIiqAvp"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler=StandardScaler()"
      ],
      "metadata": {
        "id": "bmEjq7l2qM9k"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=scaler.fit_transform(X_train)\n",
        "X_valid=scaler.transform(X_valid)\n",
        "X_test=scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "tKUttN2fqS8M"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "Ft6rc4maqf6S"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mean_squared_error', optimizer='sgd')"
      ],
      "metadata": {
        "id": "lMAl6FdQqpVl"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Egk_jlEoqtZa",
        "outputId": "c6876d4a-c488-443f-84ed-f1531cc2d628"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 2s 3ms/step - loss: 0.8127 - val_loss: 1.5442\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4693 - val_loss: 0.5879\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4152 - val_loss: 0.4290\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.3897\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3869 - val_loss: 0.4199\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3791 - val_loss: 0.4504\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3741 - val_loss: 0.4788\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3703 - val_loss: 0.4859\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3656 - val_loss: 0.4098\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3701 - val_loss: 0.3932\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.4531\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3568 - val_loss: 0.5026\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3595 - val_loss: 0.4258\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.3857\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.4920\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.4161\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3436 - val_loss: 0.3731\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3424 - val_loss: 0.3908\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3405 - val_loss: 0.3610\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3385 - val_loss: 0.3436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test=model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHV-EHdkqy0S",
        "outputId": "08378a0e-d249-4b5d-9e5e-3f56a03b29b3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.3645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new=X_test[:3]\n",
        "y_pred=model.predict(X_new)"
      ],
      "metadata": {
        "id": "SB06JJ7Mq3u-"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#순차적이지 않은 신경망의 예\n",
        "input_=keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1=keras.layers.Dense(30, activation='relu')(input_)\n",
        "hidden2=keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat=keras.layers.Concatenate()([input_, hidden2])\n",
        "output=keras.layers.Dense(1)(concat)\n",
        "model=keras.Model(inputs=[input_], outputs=[output])"
      ],
      "metadata": {
        "id": "0QMVnFcTq7pG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#어떤 입력은 짧은 경로, 어떤 입력은 복잡한 경로를 통해 간 후 얻어지는 output을 알고 싶을때\n",
        "input_A=keras.layers.Input(shape=[5], name='wide_input')\n",
        "input_B=keras.layers.Input(shape=[6], name='deep_input')\n",
        "hidden1=keras.layers.Dense(30, activation='relu')(input_B)\n",
        "hidden2=keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat=keras.layers.concatenate([input_A, hidden2])\n",
        "output=keras.layers.Dense(1, name='output')(concat)\n",
        "model=keras.Model(inputs=[input_A, input_B], outputs=[output])"
      ],
      "metadata": {
        "id": "-H2CBVL0rn-4"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse', optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
      ],
      "metadata": {
        "id": "YjdinheYsyl7"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_A, X_train_B=X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B=X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B=X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B=X_test_A[:3], X_test_B[:3]"
      ],
      "metadata": {
        "id": "I8axYgTRtLpm"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit((X_train_A, X_train_B), y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZFxEtsHtevt",
        "outputId": "0bb0106f-ea72-4f88-b9d9-71851fa15a76"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 2.5074 - val_loss: 1.9161\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.8412 - val_loss: 0.9981\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6644 - val_loss: 0.7219\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5928 - val_loss: 0.6035\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5497 - val_loss: 0.5587\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.5201 - val_loss: 0.5400\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4984 - val_loss: 0.5293\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4819 - val_loss: 0.5314\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4694 - val_loss: 0.5433\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4597 - val_loss: 0.5732\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4515 - val_loss: 0.6050\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4447 - val_loss: 0.6328\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4396 - val_loss: 0.6218\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4347 - val_loss: 0.6529\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4307 - val_loss: 0.6788\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4274 - val_loss: 0.6800\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4242 - val_loss: 0.7146\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4215 - val_loss: 0.7538\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4189 - val_loss: 0.7864\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4166 - val_loss: 0.7908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test=model.evaluate((X_test_A, X_test_B), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qes4JAijtngj",
        "outputId": "64f2f158-5841-424e-9197-37c37447e90d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.5174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict((X_new_A, X_new_B))"
      ],
      "metadata": {
        "id": "WWDkBtz5tuVg"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arxAVUP7txNw",
        "outputId": "4ca9dc7c-925b-4505-c20c-89a57516a235"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.4708468],\n",
              "       [3.7078018],\n",
              "       [2.3278737]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#보조 출력 추가\n",
        "input_A=keras.layers.Input(shape=[5], name='wide_input')\n",
        "input_B=keras.layers.Input(shape=[6], name='deep_input')\n",
        "hidden1=keras.layers.Dense(30, activation='relu')(input_B)\n",
        "hidden2=keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat=keras.layers.concatenate([input_A, hidden2])\n",
        "output=keras.layers.Dense(1, name='main_output')(concat)\n",
        "aux_output=keras.layers.Dense(1, name='aux_output')(hidden2)\n",
        "model=keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
      ],
      "metadata": {
        "id": "dXPXUWyTuBYh"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#각 출력은 자신만의 손실함수 필요 ==> 나열된 손실을 모두 더하여 최종 손실을 구해 훈련에 사용\n",
        "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd')"
      ],
      "metadata": {
        "id": "Ysown2O5ugIY"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahSH7SJ8uxLE",
        "outputId": "6f140633-9f5d-4b68-a86c-4363892d3fe3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 3s 5ms/step - loss: 0.8844 - main_output_loss: 0.7876 - aux_output_loss: 1.7557 - val_loss: 0.5994 - val_main_output_loss: 0.5185 - val_aux_output_loss: 1.3270\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4955 - main_output_loss: 0.4423 - aux_output_loss: 0.9737 - val_loss: 0.6983 - val_main_output_loss: 0.6711 - val_aux_output_loss: 0.9431\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4460 - main_output_loss: 0.4049 - aux_output_loss: 0.8155 - val_loss: 0.8632 - val_main_output_loss: 0.8715 - val_aux_output_loss: 0.7888\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4274 - main_output_loss: 0.3957 - aux_output_loss: 0.7135 - val_loss: 0.5547 - val_main_output_loss: 0.5382 - val_aux_output_loss: 0.7036\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4173 - main_output_loss: 0.3905 - aux_output_loss: 0.6585 - val_loss: 0.4972 - val_main_output_loss: 0.4805 - val_aux_output_loss: 0.6472\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4085 - main_output_loss: 0.3859 - aux_output_loss: 0.6123 - val_loss: 0.5361 - val_main_output_loss: 0.5286 - val_aux_output_loss: 0.6037\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4050 - main_output_loss: 0.3848 - aux_output_loss: 0.5863 - val_loss: 0.5808 - val_main_output_loss: 0.5790 - val_aux_output_loss: 0.5967\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3962 - main_output_loss: 0.3772 - aux_output_loss: 0.5668 - val_loss: 0.5806 - val_main_output_loss: 0.5745 - val_aux_output_loss: 0.6353\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3899 - main_output_loss: 0.3719 - aux_output_loss: 0.5518 - val_loss: 0.4881 - val_main_output_loss: 0.4761 - val_aux_output_loss: 0.5962\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3870 - main_output_loss: 0.3701 - aux_output_loss: 0.5392 - val_loss: 0.4568 - val_main_output_loss: 0.4385 - val_aux_output_loss: 0.6221\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3829 - main_output_loss: 0.3666 - aux_output_loss: 0.5302 - val_loss: 0.5280 - val_main_output_loss: 0.5065 - val_aux_output_loss: 0.7220\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3785 - main_output_loss: 0.3631 - aux_output_loss: 0.5168 - val_loss: 0.5633 - val_main_output_loss: 0.5306 - val_aux_output_loss: 0.8580\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3734 - main_output_loss: 0.3583 - aux_output_loss: 0.5089 - val_loss: 0.4861 - val_main_output_loss: 0.4516 - val_aux_output_loss: 0.7974\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3707 - main_output_loss: 0.3562 - aux_output_loss: 0.5012 - val_loss: 0.5457 - val_main_output_loss: 0.4964 - val_aux_output_loss: 0.9893\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3664 - main_output_loss: 0.3520 - aux_output_loss: 0.4955 - val_loss: 0.4539 - val_main_output_loss: 0.4129 - val_aux_output_loss: 0.8233\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3628 - main_output_loss: 0.3489 - aux_output_loss: 0.4874 - val_loss: 0.5008 - val_main_output_loss: 0.4497 - val_aux_output_loss: 0.9603\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3629 - main_output_loss: 0.3494 - aux_output_loss: 0.4837 - val_loss: 0.4461 - val_main_output_loss: 0.4026 - val_aux_output_loss: 0.8373\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3579 - main_output_loss: 0.3446 - aux_output_loss: 0.4777 - val_loss: 0.5058 - val_main_output_loss: 0.4418 - val_aux_output_loss: 1.0817\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3514 - main_output_loss: 0.3381 - aux_output_loss: 0.4710 - val_loss: 0.6761 - val_main_output_loss: 0.5985 - val_aux_output_loss: 1.3742\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3479 - main_output_loss: 0.3350 - aux_output_loss: 0.4640 - val_loss: 0.5856 - val_main_output_loss: 0.5282 - val_aux_output_loss: 1.1030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss, main_loss, aux_loss=model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-xCp2PXu8Ai",
        "outputId": "53c7aa67-fb14-42ed-e33d-f8d780790d01"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.4472 - main_output_loss: 0.4235 - aux_output_loss: 0.6605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_main, y_pred_aux=model.predict([X_new_A, X_new_B])"
      ],
      "metadata": {
        "id": "h-0d3eNBvCug"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred_main)\n",
        "print(y_pred_aux)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWfu42ggvJA_",
        "outputId": "b6bd19a0-c62f-4002-9a4e-ab5dfe849160"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.0513682]\n",
            " [3.644383 ]\n",
            " [2.6223447]]\n",
            "[[2.1117468]\n",
            " [2.7940474]\n",
            " [2.395787 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#서브클래싱 API\n",
        "class WideAndDeepModel(keras.Model):\n",
        "    def __init__(self, units=30, activation='relu', **kwargs):\n",
        "        super().__init__(**kwargs) #표준 매개변수를 처리\n",
        "        self.hidden1=keras.layers.Dense(units, activation=activation)\n",
        "        self.hidden2=keras.layers.Dense(units, activation=activation)\n",
        "        self.main_output=keras.layers.Dense(1)\n",
        "        self.aux_output=keras.layers.Dense(1)\n",
        "\n",
        "    def call(self ,inputs):\n",
        "        input_A, input_B=inputs\n",
        "        hidden1=self.hidden1(input_B)\n",
        "        hidden2=self.hidden2(hidden1)\n",
        "        concat=keras.layers.concatenate([input_A, hidden2])\n",
        "        main_output=self.main_output(concat)\n",
        "        aux_output=self.aux_output(hidden2)\n",
        "        return  main_output, aux_output"
      ],
      "metadata": {
        "id": "DZM6cLcmvKi5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model=keras.models.Sequential([]) ==> 모델 만든후\n",
        "\n",
        "model.compile ==> 컴파일\n",
        "\n",
        "model.fit ==> 훈련\n",
        "\n",
        "model.save('my_keras_model.h5') ==> 모델 저장\n",
        "\n",
        "model=keras.models.load_model('my_keras_model.h5') ==> 모델 불러오기"
      ],
      "metadata": {
        "id": "rIqdp-XxxFHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일정한 간격으로 모델의 체크포인트를 저장 ==> callbacks"
      ],
      "metadata": {
        "id": "67gyh3kax39U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#콜백 사용하기\n",
        "#.... 모델 만들고 컴파일\n",
        "checkpoint_cb=keras.callbacks.ModelCheckpoint('my_keras_model.h5')\n",
        "history=model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
      ],
      "metadata": {
        "id": "5zz8xBAkw4QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_cb=keras.callbacks.ModelCheckpoint('my_keras.model.h5', save_best_only=True) #==> 최상의 검증 세트 점수에만 모델 저장\n",
        "history=model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb])\n",
        "model.keras.models.load_model('my_keras_model.h5') #==> 최상의 모델로 복원"
      ],
      "metadata": {
        "id": "RtqVAJJ1x8LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#조기 종료 구현 ==> 검증 세트에 대한 점수가 향상되지 않으면 훈련을 멈춤\n",
        "early_stopping_cb=keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "history=model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callback=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "id": "RBzLhd-pyUt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8ufhIrlvziJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.3 신경망 하이퍼파라미터 튜닝하기"
      ],
      "metadata": {
        "id": "OLmEC4oKzjke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
        "    model=keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "8hJekqr3zmsO"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_reg=keras.wrappers.scikit_learn.KerasRegressor(build_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nfj4winI0zVB",
        "outputId": "fbfcdbc7-24a7-4ff0-fe79-fb7cf321256e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf1JeorU06PU",
        "outputId": "89810e17-b0bd-44da-dd0c-ac377d5a472b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 1.1221 - val_loss: 0.8362\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5775 - val_loss: 0.7217\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4904 - val_loss: 0.5804\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4431 - val_loss: 0.5388\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4190 - val_loss: 0.4895\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4119\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3958 - val_loss: 0.7325\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3889 - val_loss: 0.5830\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3836 - val_loss: 0.4224\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3805 - val_loss: 0.4589\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3786 - val_loss: 0.3967\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.4517\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3739 - val_loss: 0.4442\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3732 - val_loss: 0.3882\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3697 - val_loss: 0.5187\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3685 - val_loss: 0.4507\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3666 - val_loss: 0.3852\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3659 - val_loss: 0.4678\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3678 - val_loss: 0.4004\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3641 - val_loss: 0.3859\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3634 - val_loss: 0.3771\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3616 - val_loss: 0.3807\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3608 - val_loss: 0.3889\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3596 - val_loss: 0.3948\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3591 - val_loss: 0.3974\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3586 - val_loss: 0.3845\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3571 - val_loss: 0.3707\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3560 - val_loss: 0.4249\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3561 - val_loss: 0.3786\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3549 - val_loss: 0.3853\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.3532 - val_loss: 0.3667\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3529 - val_loss: 0.4270\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.4235\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3520 - val_loss: 0.3656\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3509 - val_loss: 0.3774\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3508 - val_loss: 0.3998\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.3640\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3521 - val_loss: 0.3657\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 0.4023\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3474 - val_loss: 0.5100\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3471 - val_loss: 0.3644\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3466 - val_loss: 0.3997\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3470 - val_loss: 0.3722\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3448 - val_loss: 0.5894\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3456 - val_loss: 0.3606\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.3562\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 0.3584\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3435 - val_loss: 0.3602\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3428 - val_loss: 0.3706\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3431 - val_loss: 0.3888\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3415 - val_loss: 0.5079\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3413 - val_loss: 0.3572\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3407 - val_loss: 0.3697\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3412 - val_loss: 0.3760\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3401 - val_loss: 0.4092\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3413 - val_loss: 0.3580\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faad04f3150>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test=keras_reg.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB0iUeZL2klM",
        "outputId": "bf2730e8-ea8e-453a-d2de-97f498c173f5"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.3687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=keras_reg.predict(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DZsc69N2nxJ",
        "outputId": "212eb541-7d37-4d47-d0e7-3a06c1065184"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faacf572b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distribs={\n",
        "    \"n_hidden\":[0,1,2,3],\n",
        "    \"n_neurons\":np.arange(1,100),\n",
        "    \"learning_rate\":reciprocal(3e-4, 3e-2),\n",
        "}"
      ],
      "metadata": {
        "id": "xRwmF16a2ptD"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_search_cv=RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)"
      ],
      "metadata": {
        "id": "0GVCSnF93Dna"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_search_cv.fit(X_train ,y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpGWOIDw3JM4",
        "outputId": "f3a46b7c-299c-4a04-9bc5-abb4ce389d49"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 5.0552 - val_loss: 56.6847\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 3.0462 - val_loss: 21.9355\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 1.9796 - val_loss: 7.6099\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 1.3985 - val_loss: 2.5542\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.0763 - val_loss: 1.0320\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.8931 - val_loss: 1.0605\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7881 - val_loss: 1.4880\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7262 - val_loss: 2.0834\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6883 - val_loss: 2.5900\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6643 - val_loss: 3.0454\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6481 - val_loss: 3.4862\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6366 - val_loss: 3.6099\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6280 - val_loss: 3.8329\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6207 - val_loss: 4.0819\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6148 - val_loss: 4.0193\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5942\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 6.7138 - val_loss: 72.7979\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 3.8455 - val_loss: 41.7263\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.4078 - val_loss: 23.0359\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.6477 - val_loss: 11.9227\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.2279 - val_loss: 5.5066\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.9865 - val_loss: 2.1703\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.8429 - val_loss: 0.8775\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7543 - val_loss: 0.9360\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6974 - val_loss: 1.8896\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6594 - val_loss: 3.4319\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6328 - val_loss: 5.3386\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6135 - val_loss: 7.4501\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5988 - val_loss: 9.6348\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5872 - val_loss: 11.8251\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5777 - val_loss: 13.9819\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5698 - val_loss: 16.0327\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5630 - val_loss: 17.9616\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.6811\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 4.7897 - val_loss: 3.8518\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 2.8872 - val_loss: 2.9407\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.8581 - val_loss: 2.5928\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.2916 - val_loss: 2.7507\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.9767 - val_loss: 2.9249\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8004 - val_loss: 2.9550\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7000 - val_loss: 3.1560\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6426 - val_loss: 3.1953\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6089 - val_loss: 3.1168\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5890 - val_loss: 3.2619\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5767 - val_loss: 3.3650\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5687 - val_loss: 3.4891\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5633 - val_loss: 3.5767\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5563\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 6.8211 - val_loss: 36.6500\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.0115 - val_loss: 15.4289\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.6753 - val_loss: 7.8739\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1304 - val_loss: 5.3075\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.8887 - val_loss: 4.1906\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7737 - val_loss: 4.2133\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7159 - val_loss: 3.8814\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6824 - val_loss: 3.8124\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6616 - val_loss: 3.7961\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6471 - val_loss: 3.7562\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6351 - val_loss: 4.1552\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6260 - val_loss: 3.8279\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6177 - val_loss: 3.8151\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6097 - val_loss: 4.1457\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6033 - val_loss: 4.1112\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5970 - val_loss: 3.7076\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5911 - val_loss: 3.7535\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5856 - val_loss: 3.6540\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5800 - val_loss: 3.9784\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5754 - val_loss: 3.3849\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5710 - val_loss: 3.3703\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5667 - val_loss: 3.0634\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5629 - val_loss: 3.1979\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5592 - val_loss: 3.0927\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5556 - val_loss: 3.4470\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5514 - val_loss: 4.0390\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5496 - val_loss: 3.5062\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5465 - val_loss: 3.4177\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5429 - val_loss: 3.9519\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5415 - val_loss: 3.5207\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5389 - val_loss: 3.4763\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5365 - val_loss: 3.1590\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5234\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 4.7448 - val_loss: 3.9907\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 2.1069 - val_loss: 5.8193\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.1659 - val_loss: 9.3615\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.8036 - val_loss: 13.1487\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6564 - val_loss: 16.5881\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5930 - val_loss: 19.6299\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5638 - val_loss: 22.0960\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5490 - val_loss: 24.0601\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5402 - val_loss: 25.6594\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5342 - val_loss: 26.8746\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5294 - val_loss: 27.9447\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.7267\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 5.5483 - val_loss: 4.6325\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 2.4577 - val_loss: 1.7597\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.3324 - val_loss: 2.2831\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.9022 - val_loss: 3.1194\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7311 - val_loss: 3.6034\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6576 - val_loss: 4.4535\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6256 - val_loss: 4.4962\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6084 - val_loss: 3.9976\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5976 - val_loss: 4.1756\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5901 - val_loss: 3.8955\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5829 - val_loss: 4.4583\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5780 - val_loss: 4.4814\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5675\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 5ms/step - loss: 0.6360 - val_loss: 3.5121\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4172 - val_loss: 0.8925\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4146 - val_loss: 0.5942\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3856 - val_loss: 0.7194\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3520 - val_loss: 0.6726\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3457 - val_loss: 1.4742\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3665 - val_loss: 1.2379\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3369 - val_loss: 1.1190\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3298 - val_loss: 0.3333\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3259 - val_loss: 0.3291\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3203 - val_loss: 0.3313\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3178 - val_loss: 0.3361\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3152 - val_loss: 0.3195\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3111 - val_loss: 1.9505\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3111 - val_loss: 0.3917\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3052 - val_loss: 0.3824\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3045 - val_loss: 0.6775\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3030 - val_loss: 0.3130\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2970 - val_loss: 0.3362\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3002 - val_loss: 0.3214\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2995 - val_loss: 0.3105\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2940 - val_loss: 0.3031\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2890 - val_loss: 0.3246\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2959 - val_loss: 0.9688\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.2897 - val_loss: 0.3433\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2856 - val_loss: 0.4726\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2836 - val_loss: 0.4869\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2829 - val_loss: 3.3276\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2820 - val_loss: 1.7626\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2816 - val_loss: 0.7624\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2819 - val_loss: 2.0149\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2815 - val_loss: 0.9042\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.2907\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 5ms/step - loss: 0.6346 - val_loss: 1.1344\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3884 - val_loss: 1.2225\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3631 - val_loss: 1.3288\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3569 - val_loss: 0.9482\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3452 - val_loss: 0.6748\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3376 - val_loss: 0.4284\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3303 - val_loss: 0.5620\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3260 - val_loss: 0.4314\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3225 - val_loss: 0.5065\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3188 - val_loss: 0.3603\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3159 - val_loss: 0.3400\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3142 - val_loss: 1.4987\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3114 - val_loss: 0.3267\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3072 - val_loss: 0.3834\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3021 - val_loss: 0.3785\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3010 - val_loss: 0.3418\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2988 - val_loss: 0.4504\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2968 - val_loss: 0.4945\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2938 - val_loss: 0.5894\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2917 - val_loss: 0.4167\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2892 - val_loss: 0.4944\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2881 - val_loss: 0.3099\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2900 - val_loss: 0.4836\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2840 - val_loss: 0.6354\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2835 - val_loss: 0.5845\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2814 - val_loss: 1.0380\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2801 - val_loss: 0.3456\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2778 - val_loss: 0.5111\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2774 - val_loss: 0.4561\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2743 - val_loss: 0.5912\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2744 - val_loss: 1.4550\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2748 - val_loss: 0.7757\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.2972\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6715 - val_loss: 2.8250\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4025 - val_loss: 0.6674\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3676 - val_loss: 0.5511\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 0.3955\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3415 - val_loss: 0.4164\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3355 - val_loss: 0.3478\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3283 - val_loss: 0.5347\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3249 - val_loss: 0.4097\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3206 - val_loss: 0.5108\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3152 - val_loss: 0.4038\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3121 - val_loss: 0.5352\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3081 - val_loss: 0.5120\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3036 - val_loss: 0.6885\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3024 - val_loss: 0.4554\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3033 - val_loss: 0.3746\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2974 - val_loss: 0.3697\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3208\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.2265 - val_loss: 15.9516\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3727 - val_loss: 7.3656\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9071 - val_loss: 3.0459\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7153 - val_loss: 1.2389\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6343 - val_loss: 0.7599\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5961 - val_loss: 0.6759\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5734 - val_loss: 0.6066\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5555 - val_loss: 0.5621\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5407 - val_loss: 0.5605\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 0.5507\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5153 - val_loss: 0.5427\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5042 - val_loss: 0.5408\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4940 - val_loss: 0.5338\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4848 - val_loss: 0.5263\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4762 - val_loss: 0.5002\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4685 - val_loss: 0.5000\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4613 - val_loss: 0.4979\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4549 - val_loss: 0.4976\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4490 - val_loss: 0.5024\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4434 - val_loss: 0.4828\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 0.4926\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4340 - val_loss: 0.4743\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4297 - val_loss: 0.4921\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4258 - val_loss: 0.4722\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4221 - val_loss: 0.4701\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4189 - val_loss: 0.4728\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4158 - val_loss: 0.4538\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4129 - val_loss: 0.4916\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4103 - val_loss: 0.4832\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4078 - val_loss: 0.4895\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4056 - val_loss: 0.4807\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4035 - val_loss: 0.4634\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4014 - val_loss: 0.4822\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3993 - val_loss: 0.5053\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3977 - val_loss: 0.4603\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.4573\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3943 - val_loss: 0.4584\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3912\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.6670 - val_loss: 41.5621\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.2317 - val_loss: 34.7913\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9136 - val_loss: 19.6778\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7824 - val_loss: 10.4176\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7125 - val_loss: 4.7394\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6666 - val_loss: 1.9501\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6327 - val_loss: 0.8581\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6058 - val_loss: 0.5972\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5831 - val_loss: 0.7546\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5634 - val_loss: 1.0626\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5464 - val_loss: 1.3705\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5312 - val_loss: 1.6056\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5175 - val_loss: 1.7692\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5053 - val_loss: 1.9021\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 1.9101\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 1.9759\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4752 - val_loss: 1.9360\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4669 - val_loss: 1.8900\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4758\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.9451 - val_loss: 8.1904\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1181 - val_loss: 5.2571\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7864 - val_loss: 2.8063\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6893 - val_loss: 1.6057\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6445 - val_loss: 1.0881\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6176 - val_loss: 0.8567\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5969 - val_loss: 0.7724\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5790 - val_loss: 0.7177\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5628 - val_loss: 0.6845\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5480 - val_loss: 0.6466\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5344 - val_loss: 0.6441\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5219 - val_loss: 0.6275\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5104 - val_loss: 0.6321\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4999 - val_loss: 0.6373\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4900 - val_loss: 0.6353\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4810 - val_loss: 0.6408\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4726 - val_loss: 0.6585\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4650 - val_loss: 0.6459\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4580 - val_loss: 0.6596\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4514 - val_loss: 0.6518\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4455 - val_loss: 0.6706\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4401 - val_loss: 0.6818\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4603\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0619 - val_loss: 1.7250\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5063 - val_loss: 0.5477\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4359 - val_loss: 0.6110\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.5377\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3876 - val_loss: 0.6227\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3751 - val_loss: 0.4057\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3682 - val_loss: 0.4913\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3627 - val_loss: 0.3676\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3584 - val_loss: 2.3617\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3545 - val_loss: 0.4231\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 0.5195\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3531 - val_loss: 0.9059\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3468 - val_loss: 0.8270\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3820\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3414 - val_loss: 0.6757\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.5183\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3382 - val_loss: 0.4845\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3389 - val_loss: 0.6465\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3415\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 4ms/step - loss: 0.7927 - val_loss: 0.6340\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4452 - val_loss: 0.4525\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4022 - val_loss: 0.4786\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3799 - val_loss: 0.5914\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 1.0376\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.9362\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3532 - val_loss: 0.8515\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3498 - val_loss: 0.6666\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.4620\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3418 - val_loss: 0.4170\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3390 - val_loss: 0.3789\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3363 - val_loss: 0.3679\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3339 - val_loss: 0.3597\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3316 - val_loss: 0.3479\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3290 - val_loss: 0.3431\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3275 - val_loss: 0.3463\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3240 - val_loss: 0.4153\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3223 - val_loss: 0.3732\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3208 - val_loss: 0.3439\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3191 - val_loss: 0.4527\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3167 - val_loss: 0.3266\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3157 - val_loss: 0.3598\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3143 - val_loss: 0.5606\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3127 - val_loss: 0.5849\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3097 - val_loss: 0.4332\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3100 - val_loss: 0.5619\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3074 - val_loss: 0.5922\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3070 - val_loss: 0.6068\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3049 - val_loss: 0.6073\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3042 - val_loss: 0.7977\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3026 - val_loss: 0.7123\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3061\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8480 - val_loss: 7.5527\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4341 - val_loss: 0.4402\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.4186\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.5420\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3643 - val_loss: 0.6970\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3551 - val_loss: 0.4989\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.6533\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.8585\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3364 - val_loss: 0.9521\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3408 - val_loss: 0.3844\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.3369 - val_loss: 2.2101\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3382 - val_loss: 0.5761\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3247 - val_loss: 0.3447\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 0.3400\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3201 - val_loss: 0.4038\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3187 - val_loss: 0.6162\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3179 - val_loss: 0.6295\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3148 - val_loss: 0.3311\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3131 - val_loss: 0.3419\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3122 - val_loss: 0.3656\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3123 - val_loss: 0.7473\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3098 - val_loss: 0.4131\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3091 - val_loss: 0.4157\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3074 - val_loss: 0.3909\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3082 - val_loss: 0.3458\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3081 - val_loss: 0.3404\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3033 - val_loss: 0.3692\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3017 - val_loss: 0.6463\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3278\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.2888 - val_loss: 13.1187\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.5251 - val_loss: 17.2009\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0043 - val_loss: 15.0333\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8380 - val_loss: 12.0041\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7506 - val_loss: 9.5428\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6963 - val_loss: 7.4763\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6588 - val_loss: 5.9087\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6322 - val_loss: 4.9878\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6116 - val_loss: 4.2827\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5950 - val_loss: 3.7233\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5809 - val_loss: 3.2711\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5688 - val_loss: 3.0017\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5583 - val_loss: 2.8191\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5488 - val_loss: 2.6565\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5403 - val_loss: 2.5099\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5326 - val_loss: 2.3944\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5255 - val_loss: 2.2764\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5189 - val_loss: 2.1673\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5127 - val_loss: 2.0817\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5069 - val_loss: 1.9820\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5015 - val_loss: 1.9006\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4964 - val_loss: 1.8243\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4915 - val_loss: 1.7484\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4868 - val_loss: 1.6730\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4826 - val_loss: 1.6255\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4783 - val_loss: 1.5793\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4746 - val_loss: 1.5229\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4709 - val_loss: 1.4664\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4673 - val_loss: 1.4168\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4639 - val_loss: 1.3855\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4608 - val_loss: 1.3432\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4576 - val_loss: 1.3152\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4545 - val_loss: 1.2822\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4518 - val_loss: 1.2524\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4490 - val_loss: 1.2216\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4463 - val_loss: 1.2016\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4438 - val_loss: 1.1717\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4413 - val_loss: 1.1479\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4389 - val_loss: 1.1345\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4365 - val_loss: 1.1154\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4344 - val_loss: 1.0856\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4322 - val_loss: 1.0701\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4300 - val_loss: 1.0703\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4281 - val_loss: 1.0505\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 1.0244\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 1.0129\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4224 - val_loss: 1.0001\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.9930\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4189 - val_loss: 0.9745\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4171 - val_loss: 0.9544\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4156 - val_loss: 0.9469\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4139 - val_loss: 0.9410\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4124 - val_loss: 0.9261\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4109 - val_loss: 0.9104\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4095 - val_loss: 0.9013\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4080 - val_loss: 0.8849\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4067 - val_loss: 0.8794\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4053 - val_loss: 0.8695\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.8603\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4028 - val_loss: 0.8561\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4015 - val_loss: 0.8486\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4003 - val_loss: 0.8401\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3991 - val_loss: 0.8326\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.8191\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3968 - val_loss: 0.8155\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3957 - val_loss: 0.8031\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3946 - val_loss: 0.7977\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3936 - val_loss: 0.7883\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3926 - val_loss: 0.7819\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.7711\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3905 - val_loss: 0.7663\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3894 - val_loss: 0.7463\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3888 - val_loss: 0.7493\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3879 - val_loss: 0.7413\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.7335\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3861 - val_loss: 0.7284\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3853 - val_loss: 0.7157\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3845 - val_loss: 0.7096\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.7050\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.6998\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3822 - val_loss: 0.6897\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3814 - val_loss: 0.6737\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.6704\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3800 - val_loss: 0.6705\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3794 - val_loss: 0.6623\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.6559\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3780 - val_loss: 0.6500\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3774 - val_loss: 0.6474\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3768 - val_loss: 0.6387\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3762 - val_loss: 0.6358\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.6301\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.6301\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3744 - val_loss: 0.6239\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3739 - val_loss: 0.6201\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3734 - val_loss: 0.6164\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3728 - val_loss: 0.6127\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3723 - val_loss: 0.6014\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.5997\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3712 - val_loss: 0.5905\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3707 - val_loss: 0.5963\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3652\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.2075 - val_loss: 4.8376\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4590 - val_loss: 6.9213\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0895 - val_loss: 6.7887\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9471 - val_loss: 5.9843\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8535 - val_loss: 5.2618\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7884 - val_loss: 4.8123\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7416 - val_loss: 4.3177\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7069 - val_loss: 4.0005\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6797 - val_loss: 3.6747\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6574 - val_loss: 3.3933\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6382 - val_loss: 3.1411\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6211 - val_loss: 2.9305\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6056 - val_loss: 2.7414\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5913 - val_loss: 2.5879\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5780 - val_loss: 2.4112\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5660 - val_loss: 2.3017\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5544 - val_loss: 2.2054\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5435 - val_loss: 2.1042\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5332 - val_loss: 2.0111\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5233 - val_loss: 1.8871\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5139 - val_loss: 1.8666\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5052 - val_loss: 1.7929\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4969 - val_loss: 1.7137\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4888 - val_loss: 1.6455\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4811 - val_loss: 1.6183\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4741 - val_loss: 1.5421\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4674 - val_loss: 1.5246\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4611 - val_loss: 1.4780\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4551 - val_loss: 1.4580\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 1.4324\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4442 - val_loss: 1.4109\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4393 - val_loss: 1.3947\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4348 - val_loss: 1.3786\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4304 - val_loss: 1.3608\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4265 - val_loss: 1.3680\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4226 - val_loss: 1.3779\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4191 - val_loss: 1.3718\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4159 - val_loss: 1.3711\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4126 - val_loss: 1.3999\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 1.4004\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4070 - val_loss: 1.3997\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4044 - val_loss: 1.4005\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4018 - val_loss: 1.4009\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3996 - val_loss: 1.4495\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3997\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.5519 - val_loss: 8.2074\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.8101 - val_loss: 10.1376\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1359 - val_loss: 7.7982\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8826 - val_loss: 4.9246\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7668 - val_loss: 3.3756\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7093 - val_loss: 2.4323\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6751 - val_loss: 1.8525\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6513 - val_loss: 1.4909\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6325 - val_loss: 1.2214\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6168 - val_loss: 1.0282\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6031 - val_loss: 0.8847\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5910 - val_loss: 0.8086\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5803 - val_loss: 0.7358\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5703 - val_loss: 0.6798\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5612 - val_loss: 0.6426\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5525 - val_loss: 0.6069\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5447 - val_loss: 0.5874\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5371 - val_loss: 0.5687\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5300 - val_loss: 0.5539\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5233 - val_loss: 0.5412\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5169 - val_loss: 0.5315\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5108 - val_loss: 0.5217\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5050 - val_loss: 0.5147\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4995 - val_loss: 0.5084\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4942 - val_loss: 0.5020\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4891 - val_loss: 0.4972\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4842 - val_loss: 0.4918\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4794 - val_loss: 0.4871\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4749 - val_loss: 0.4828\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4706 - val_loss: 0.4791\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4663 - val_loss: 0.4753\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4622 - val_loss: 0.4728\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4585 - val_loss: 0.4687\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4548 - val_loss: 0.4661\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4513 - val_loss: 0.4633\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4478 - val_loss: 0.4614\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4445 - val_loss: 0.4593\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4414 - val_loss: 0.4598\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4384 - val_loss: 0.4572\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4355 - val_loss: 0.4541\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4328 - val_loss: 0.4535\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4301 - val_loss: 0.4543\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4275 - val_loss: 0.4535\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4251 - val_loss: 0.4545\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4228 - val_loss: 0.4565\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4205 - val_loss: 0.4559\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4184 - val_loss: 0.4574\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4163 - val_loss: 0.4608\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4143 - val_loss: 0.4615\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4124 - val_loss: 0.4654\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4658\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4369\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1384 - val_loss: 1.1448\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 0.7524\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4642 - val_loss: 0.5182\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4302 - val_loss: 0.4297\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.5149\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3985 - val_loss: 0.5074\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.6274\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.4608\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.3850\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3758 - val_loss: 0.5162\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3714 - val_loss: 0.4108\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3678 - val_loss: 0.3747\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3656 - val_loss: 0.3920\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3639 - val_loss: 0.3665\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.3869\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3692\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3569 - val_loss: 0.3664\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3551 - val_loss: 0.3822\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3558 - val_loss: 0.3794\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.4972\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3512 - val_loss: 0.4676\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3494 - val_loss: 0.3695\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3484 - val_loss: 0.3764\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3467 - val_loss: 0.3534\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3457 - val_loss: 0.3738\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3447 - val_loss: 0.3536\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3447 - val_loss: 0.3534\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3433 - val_loss: 0.4526\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3424 - val_loss: 0.4387\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3408 - val_loss: 0.3863\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3399 - val_loss: 0.3463\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3392 - val_loss: 0.4138\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3381 - val_loss: 0.3475\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3371 - val_loss: 0.3597\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3372 - val_loss: 0.3635\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3456\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3361 - val_loss: 0.4484\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3385 - val_loss: 0.5600\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3380 - val_loss: 0.3471\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3338 - val_loss: 0.3430\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3340 - val_loss: 0.8622\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3337 - val_loss: 0.3403\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3637\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.4309\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3307 - val_loss: 0.3383\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3313 - val_loss: 0.4908\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3307 - val_loss: 0.3622\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3296 - val_loss: 0.3381\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3315 - val_loss: 0.3986\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3289 - val_loss: 0.3558\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3272 - val_loss: 0.3746\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3270 - val_loss: 0.5076\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3275 - val_loss: 0.4321\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.4280\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3266 - val_loss: 0.3959\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3256 - val_loss: 0.7359\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3531\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3253 - val_loss: 0.5040\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3292\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.2064 - val_loss: 0.7874\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5593 - val_loss: 0.5166\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.4751\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4523 - val_loss: 0.5289\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4308 - val_loss: 0.7261\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4153 - val_loss: 1.1453\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4049 - val_loss: 1.3819\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3968 - val_loss: 1.6219\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3914 - val_loss: 1.7214\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3864 - val_loss: 2.1238\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3819 - val_loss: 1.9397\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 2.1188\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3748 - val_loss: 2.2265\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3847\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 3ms/step - loss: 1.1747 - val_loss: 0.6160\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5321 - val_loss: 0.7609\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4680 - val_loss: 0.7540\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4328 - val_loss: 1.3109\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4129 - val_loss: 0.8838\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4010 - val_loss: 0.7553\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3902 - val_loss: 0.8654\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3830 - val_loss: 0.6174\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.6129\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3743 - val_loss: 0.4361\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3707 - val_loss: 0.4867\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3673 - val_loss: 0.4578\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3641 - val_loss: 0.5758\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3626 - val_loss: 0.7869\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3598 - val_loss: 0.4176\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3573 - val_loss: 0.5613\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.4098\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3536 - val_loss: 0.3840\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3523 - val_loss: 0.3900\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3503 - val_loss: 0.4041\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3495 - val_loss: 0.6565\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3479 - val_loss: 0.4031\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.4234\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3456 - val_loss: 0.3880\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3764\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3421 - val_loss: 0.5073\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3421 - val_loss: 0.3602\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3399 - val_loss: 0.4233\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.3718\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3381 - val_loss: 0.4691\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3379 - val_loss: 0.3782\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3369 - val_loss: 0.4658\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3354 - val_loss: 0.4137\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3361 - val_loss: 0.5387\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3342 - val_loss: 0.3588\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.4104\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3329 - val_loss: 0.4540\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.3691\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3319 - val_loss: 0.3550\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3295 - val_loss: 0.5318\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3289 - val_loss: 0.3591\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3289 - val_loss: 0.3497\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3272 - val_loss: 0.3564\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3275 - val_loss: 0.4072\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.3605\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3258 - val_loss: 0.3812\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3254 - val_loss: 0.5127\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3246 - val_loss: 0.3567\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3236 - val_loss: 0.3669\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3214 - val_loss: 0.3561\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3775\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3218 - val_loss: 0.4444\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3514\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 6.9037 - val_loss: 39.1206\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 5.0940 - val_loss: 33.1748\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.8391 - val_loss: 28.1153\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.9534 - val_loss: 24.0073\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.3203 - val_loss: 20.3522\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.8626 - val_loss: 17.3515\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.5283 - val_loss: 14.9497\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.2830 - val_loss: 12.9549\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1019 - val_loss: 11.2593\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9671 - val_loss: 9.9570\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8666 - val_loss: 8.7620\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7913 - val_loss: 7.9700\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7349 - val_loss: 7.2818\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6924 - val_loss: 6.7479\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6603 - val_loss: 6.3004\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6359 - val_loss: 5.8188\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6172 - val_loss: 5.4638\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6029 - val_loss: 5.1869\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5918 - val_loss: 4.9480\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5832 - val_loss: 4.7945\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5765 - val_loss: 4.6488\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5711 - val_loss: 4.5437\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5668 - val_loss: 4.3925\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5633 - val_loss: 4.2677\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5603 - val_loss: 4.1665\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5578 - val_loss: 4.0770\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5557 - val_loss: 3.9970\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5539 - val_loss: 3.9575\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5522 - val_loss: 3.8747\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5508 - val_loss: 3.8290\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5494 - val_loss: 3.8743\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5482 - val_loss: 3.8279\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5470 - val_loss: 3.7626\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5460 - val_loss: 3.7555\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5449 - val_loss: 3.7910\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5439 - val_loss: 3.7916\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5430 - val_loss: 3.7250\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5421 - val_loss: 3.7425\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5412 - val_loss: 3.7689\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5404 - val_loss: 3.6810\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5396 - val_loss: 3.6989\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5387 - val_loss: 3.7005\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5379 - val_loss: 3.7090\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5372 - val_loss: 3.7232\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5364 - val_loss: 3.7095\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5357 - val_loss: 3.6891\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5350 - val_loss: 3.6803\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5343 - val_loss: 3.6753\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5336 - val_loss: 3.6965\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5330 - val_loss: 3.6947\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5323 - val_loss: 3.6840\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5317 - val_loss: 3.6860\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5310 - val_loss: 3.6338\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5304 - val_loss: 3.6581\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5298 - val_loss: 3.6760\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5293 - val_loss: 3.6531\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5287 - val_loss: 3.6585\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5281 - val_loss: 3.6927\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5275 - val_loss: 3.7066\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5270 - val_loss: 3.6830\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5265 - val_loss: 3.7119\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5260 - val_loss: 3.7228\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5254 - val_loss: 3.7446\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5122\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 5.5125 - val_loss: 5.1071\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.1417 - val_loss: 4.9886\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.1705 - val_loss: 5.4092\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.4770 - val_loss: 6.1669\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.9772 - val_loss: 7.1340\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.6152 - val_loss: 8.2227\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3506 - val_loss: 9.3734\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1567 - val_loss: 10.5473\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0136 - val_loss: 11.7162\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9075 - val_loss: 12.8686\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8283 - val_loss: 13.9927\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7690 - val_loss: 15.0820\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.8562\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 8.3306 - val_loss: 89.8126\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 6.0560 - val_loss: 67.4015\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.4877 - val_loss: 51.3951\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.3906 - val_loss: 39.8706\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.6133 - val_loss: 31.7150\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.0568 - val_loss: 25.6675\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.6543 - val_loss: 21.0841\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3610 - val_loss: 17.6553\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.1464 - val_loss: 14.8877\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9882 - val_loss: 12.8507\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8715 - val_loss: 11.1549\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7850 - val_loss: 9.8519\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7207 - val_loss: 8.7236\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6726 - val_loss: 7.9186\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6368 - val_loss: 7.2061\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6099 - val_loss: 6.5708\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5897 - val_loss: 6.1645\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5748 - val_loss: 5.7747\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5633 - val_loss: 5.4387\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5546 - val_loss: 5.1264\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5480 - val_loss: 4.8558\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5430 - val_loss: 4.6500\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5390 - val_loss: 4.4549\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5360 - val_loss: 4.2889\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5336 - val_loss: 4.2063\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5317 - val_loss: 4.1182\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5301 - val_loss: 4.0337\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5289 - val_loss: 3.9581\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5278 - val_loss: 3.9275\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5268 - val_loss: 3.9381\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5262 - val_loss: 3.8575\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5255 - val_loss: 3.7283\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5248 - val_loss: 3.7471\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5243 - val_loss: 3.7291\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5237 - val_loss: 3.7411\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5233 - val_loss: 3.6727\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5228 - val_loss: 3.6594\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5224 - val_loss: 3.6666\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5220 - val_loss: 3.6295\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5216 - val_loss: 3.5969\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5212 - val_loss: 3.5745\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5208 - val_loss: 3.5205\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5204 - val_loss: 3.4691\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5200 - val_loss: 3.4596\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5197 - val_loss: 3.4473\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5194 - val_loss: 3.3879\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5190 - val_loss: 3.3783\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5187 - val_loss: 3.3621\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5184 - val_loss: 3.3698\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5181 - val_loss: 3.3972\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5178 - val_loss: 3.3780\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5175 - val_loss: 3.3421\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5172 - val_loss: 3.3510\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5168 - val_loss: 3.3953\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5166 - val_loss: 3.3520\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5163 - val_loss: 3.3646\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5160 - val_loss: 3.3747\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5158 - val_loss: 3.3653\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5155 - val_loss: 3.3366\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5153 - val_loss: 3.3566\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5150 - val_loss: 3.3542\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5148 - val_loss: 3.3815\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5145 - val_loss: 3.3910\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5143 - val_loss: 3.3842\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5140 - val_loss: 3.3761\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5138 - val_loss: 3.3812\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5136 - val_loss: 3.3369\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5134 - val_loss: 3.3417\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5131 - val_loss: 3.3644\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5054\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.7539 - val_loss: 23.1220\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.8739 - val_loss: 12.5256\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1987 - val_loss: 5.2473\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9255 - val_loss: 2.3169\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8066 - val_loss: 1.1537\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7461 - val_loss: 0.7973\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7093 - val_loss: 0.7003\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6828 - val_loss: 0.6824\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6612 - val_loss: 0.6757\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6427 - val_loss: 0.6645\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6262 - val_loss: 0.6504\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6114 - val_loss: 0.6396\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5977 - val_loss: 0.6354\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5853 - val_loss: 0.6180\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5738 - val_loss: 0.6023\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5632 - val_loss: 0.5879\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5533 - val_loss: 0.5818\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5441 - val_loss: 0.5691\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5355 - val_loss: 0.5539\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5274 - val_loss: 0.5461\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5200 - val_loss: 0.5332\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5130 - val_loss: 0.5261\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5065 - val_loss: 0.5149\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5004 - val_loss: 0.5073\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4946 - val_loss: 0.5000\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4892 - val_loss: 0.4934\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4842 - val_loss: 0.4874\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4794 - val_loss: 0.4821\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4749 - val_loss: 0.4763\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4706 - val_loss: 0.4715\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4667 - val_loss: 0.4677\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4629 - val_loss: 0.4633\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4593 - val_loss: 0.4600\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4559 - val_loss: 0.4567\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4527 - val_loss: 0.4537\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4496 - val_loss: 0.4508\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4468 - val_loss: 0.4485\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4440 - val_loss: 0.4460\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4414 - val_loss: 0.4443\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4389 - val_loss: 0.4427\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4365 - val_loss: 0.4418\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4343 - val_loss: 0.4387\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4321 - val_loss: 0.4374\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4300 - val_loss: 0.4358\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4281 - val_loss: 0.4353\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4262 - val_loss: 0.4344\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 0.4336\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4226 - val_loss: 0.4340\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.4319\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4194 - val_loss: 0.4295\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4179 - val_loss: 0.4309\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4163 - val_loss: 0.4316\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4150 - val_loss: 0.4287\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 0.4277\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4123 - val_loss: 0.4274\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4110 - val_loss: 0.4266\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 0.4232\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4086 - val_loss: 0.4250\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4074 - val_loss: 0.4219\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4062 - val_loss: 0.4178\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4186\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4041 - val_loss: 0.4175\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4031 - val_loss: 0.4158\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4020 - val_loss: 0.4180\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4011 - val_loss: 0.4149\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4002 - val_loss: 0.4158\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3993 - val_loss: 0.4150\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3983 - val_loss: 0.4124\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3975 - val_loss: 0.4105\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3966 - val_loss: 0.4118\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.4131\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.4101\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3942 - val_loss: 0.4095\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3934 - val_loss: 0.4086\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3927 - val_loss: 0.4083\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3920 - val_loss: 0.4063\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3912 - val_loss: 0.4092\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3905 - val_loss: 0.4072\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3899 - val_loss: 0.4059\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3892 - val_loss: 0.4058\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3885 - val_loss: 0.4068\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3879 - val_loss: 0.4061\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3873 - val_loss: 0.4067\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3867 - val_loss: 0.4035\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3861 - val_loss: 0.4020\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3855 - val_loss: 0.4002\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3849 - val_loss: 0.3993\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3843 - val_loss: 0.3991\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3838 - val_loss: 0.4011\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3832 - val_loss: 0.4032\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3828 - val_loss: 0.4027\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3822 - val_loss: 0.4058\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3818 - val_loss: 0.4007\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3812 - val_loss: 0.4004\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.3983\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3802 - val_loss: 0.3950\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3798 - val_loss: 0.3949\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3794 - val_loss: 0.3952\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3789 - val_loss: 0.3931\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3784 - val_loss: 0.3954\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3734\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.9721 - val_loss: 7.7069\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.7354 - val_loss: 10.2775\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0996 - val_loss: 9.7654\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8589 - val_loss: 8.0664\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7463 - val_loss: 6.3227\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6853 - val_loss: 4.8703\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6484 - val_loss: 3.7709\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6237 - val_loss: 2.9324\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6055 - val_loss: 2.3238\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5911 - val_loss: 1.8611\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5788 - val_loss: 1.5396\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5679 - val_loss: 1.2747\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5581 - val_loss: 1.0857\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5490 - val_loss: 0.9498\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5406 - val_loss: 0.8492\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5328 - val_loss: 0.7651\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5255 - val_loss: 0.7021\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5187 - val_loss: 0.6635\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5124 - val_loss: 0.6301\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5064 - val_loss: 0.6042\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5007 - val_loss: 0.5857\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4953 - val_loss: 0.5730\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4902 - val_loss: 0.5586\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4854 - val_loss: 0.5542\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4808 - val_loss: 0.5509\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4763 - val_loss: 0.5499\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4721 - val_loss: 0.5488\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4681 - val_loss: 0.5516\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4643 - val_loss: 0.5595\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4606 - val_loss: 0.5644\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4572 - val_loss: 0.5753\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4538 - val_loss: 0.5886\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4506 - val_loss: 0.5969\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4476 - val_loss: 0.6154\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4447 - val_loss: 0.6355\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4419 - val_loss: 0.6552\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4392 - val_loss: 0.6769\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4317\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.7101 - val_loss: 8.1599\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.7806 - val_loss: 7.1220\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1377 - val_loss: 4.5876\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8658 - val_loss: 2.5215\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7468 - val_loss: 1.4329\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6910 - val_loss: 0.9044\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6613 - val_loss: 0.7298\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6417 - val_loss: 0.6618\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6264 - val_loss: 0.6382\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6133 - val_loss: 0.6172\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6012 - val_loss: 0.6044\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5899 - val_loss: 0.5937\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5791 - val_loss: 0.5833\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5689 - val_loss: 0.5747\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5592 - val_loss: 0.5664\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5501 - val_loss: 0.5612\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5413 - val_loss: 0.5549\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5332 - val_loss: 0.5485\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5254 - val_loss: 0.5417\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5181 - val_loss: 0.5434\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5110 - val_loss: 0.5396\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5045 - val_loss: 0.5382\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4984 - val_loss: 0.5436\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4926 - val_loss: 0.5433\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4871 - val_loss: 0.5467\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4821 - val_loss: 0.5510\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4772 - val_loss: 0.5511\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4727 - val_loss: 0.5597\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4684 - val_loss: 0.5602\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4643 - val_loss: 0.5711\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4605 - val_loss: 0.5747\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4569 - val_loss: 0.5810\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4662\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.9836 - val_loss: 22.3245\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.4156 - val_loss: 10.0230\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3956 - val_loss: 6.2202\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9666 - val_loss: 4.4523\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7766 - val_loss: 3.7642\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6878 - val_loss: 3.4365\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6435 - val_loss: 3.2050\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6194 - val_loss: 3.3435\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6046 - val_loss: 3.5316\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5946 - val_loss: 2.9922\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5873 - val_loss: 3.0942\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5809 - val_loss: 3.3212\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5758 - val_loss: 3.2241\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5708 - val_loss: 2.9420\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5666 - val_loss: 2.8514\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5627 - val_loss: 2.8843\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5583 - val_loss: 3.5058\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5555 - val_loss: 3.4637\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5513 - val_loss: 3.9983\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5493 - val_loss: 3.4093\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5460 - val_loss: 3.7507\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5435 - val_loss: 3.9488\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5415 - val_loss: 3.7257\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5390 - val_loss: 3.2083\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5368 - val_loss: 3.1169\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5252\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 5.3932 - val_loss: 67.8448\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.5107 - val_loss: 29.0431\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3644 - val_loss: 10.4782\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8977 - val_loss: 2.6811\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7013 - val_loss: 0.6487\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6143 - val_loss: 1.5159\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5725 - val_loss: 3.7830\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5505 - val_loss: 6.6104\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5375 - val_loss: 9.5764\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5289 - val_loss: 12.3512\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5228 - val_loss: 14.9586\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5180 - val_loss: 17.2472\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5142 - val_loss: 19.2740\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5109 - val_loss: 21.0054\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5080 - val_loss: 22.4538\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.6717\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 4.3431 - val_loss: 36.3269\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.1031 - val_loss: 18.2440\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.2599 - val_loss: 10.5843\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9269 - val_loss: 7.7683\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7920 - val_loss: 5.8721\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7305 - val_loss: 4.4580\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7001 - val_loss: 4.0245\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6814 - val_loss: 3.6699\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6685 - val_loss: 3.3354\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6576 - val_loss: 3.3229\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6485 - val_loss: 3.3515\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6400 - val_loss: 3.1724\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6321 - val_loss: 3.1908\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6235 - val_loss: 3.4140\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6184 - val_loss: 3.3863\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6116 - val_loss: 3.2550\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6046 - val_loss: 3.3583\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5990 - val_loss: 3.5962\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5944 - val_loss: 3.2696\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5888 - val_loss: 3.3143\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5839 - val_loss: 3.0329\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5800 - val_loss: 3.1577\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5756 - val_loss: 3.2509\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5714 - val_loss: 3.2732\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5675 - val_loss: 3.0428\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5642 - val_loss: 3.2414\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5608 - val_loss: 3.3802\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5576 - val_loss: 3.3181\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5547 - val_loss: 3.5782\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5522 - val_loss: 3.0232\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5494 - val_loss: 3.0928\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5470 - val_loss: 2.9988\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5447 - val_loss: 2.8077\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5420 - val_loss: 3.2208\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5404 - val_loss: 3.0370\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5381 - val_loss: 3.1716\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5355 - val_loss: 3.6941\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5350 - val_loss: 3.2854\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5320 - val_loss: 3.6444\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5320 - val_loss: 3.3174\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5301 - val_loss: 3.2976\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5286 - val_loss: 3.3068\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5268 - val_loss: 3.5073\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5151\n",
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6232 - val_loss: 0.4576\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3774 - val_loss: 0.3943\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3691 - val_loss: 0.5164\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3447 - val_loss: 0.5718\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3326 - val_loss: 0.4123\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3306 - val_loss: 0.7164\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3292 - val_loss: 1.3938\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3203 - val_loss: 0.3709\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3140 - val_loss: 0.3453\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3085 - val_loss: 0.4244\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3099 - val_loss: 0.5159\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3184 - val_loss: 0.8918\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3031 - val_loss: 4.0156\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3071 - val_loss: 2.4287\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2957 - val_loss: 0.4192\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2990 - val_loss: 10.9824\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2986 - val_loss: 2.2461\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2922 - val_loss: 0.3185\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2842 - val_loss: 0.4133\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2832 - val_loss: 0.8641\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2833 - val_loss: 1.3773\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2799 - val_loss: 0.3196\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2800 - val_loss: 1.7931\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2798 - val_loss: 0.4199\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2788 - val_loss: 10.1610\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2815 - val_loss: 0.5203\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2730 - val_loss: 0.4254\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2732 - val_loss: 0.3410\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7faad0485310>,\n",
              "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7faacf3f4690>,\n",
              "                                        'n_hidden': [0, 1, 2, 3],\n",
              "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
              "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
              "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
              "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_search_cv.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwOKa8Qm3SFL",
        "outputId": "5de003f4-e0ad-4a2d-af21-4729016ecb10"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.015137440144440517, 'n_hidden': 2, 'n_neurons': 88}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_search_cv.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coCWt47F3awA",
        "outputId": "6db9828d-bbba-47cc-fd8f-2590b1f10e84"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.3029055694739024"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=rnd_search_cv.best_estimator_.model"
      ],
      "metadata": {
        "id": "t3ixuwuI3cMQ"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XKXen3xG3o5J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}